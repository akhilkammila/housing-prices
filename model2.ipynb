{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation and Other Submissions\n",
    "Eda.ipynb and model.ipynb were my quick first model (score around 0.135)\n",
    "- No feature engineering\n",
    "- Sqrt of SalePrice\n",
    "- Ordinal encoding for all categorical variables\n",
    "- Grid search on XGBoost (single model)\n",
    "\n",
    "This model2 is now inspired by reading some other Kaggle submissions\n",
    "\n",
    "[Top 1% Solution w/ Data Leakage](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/discussion/83751)\n",
    "\n",
    "Feature Engineering\n",
    "\n",
    "1. Fill NA values (some data leakage here with using medians)\n",
    "2. Fill NA numerics w/ 0\n",
    "3. Transform numeric features with box-cox (data leakage here as well)\n",
    "4. Summed and year features (ex. bathrooms = \\sum(bathrooms))\n",
    "5. Has features (has pool, has 2nd floor, etc.)\n",
    "\n",
    "Additional Engineering\n",
    "\n",
    "6. Add dummies for categorical variables\n",
    "7. Remove columns where one value dominates\n",
    "8. Remove outliers\n",
    "\n",
    "Modelling\n",
    "\n",
    "1. Ridge Regression (Robust Scalar)\n",
    "2. Lasso Regression\n",
    "3. Elastic Net Regression\n",
    "4. Support Vector Regression\n",
    "5. Gradient Boosting Regressor\n",
    "6. Light GBM\n",
    "7. XGBoost\n",
    "8. StackingCVRegressor w/ XGBoost as meta regressor\n",
    "\n",
    "Final prediction is Blend of all previous models (including Stacking Regressor as one of those models)\n",
    "\n",
    "[Top 4% no Data Leakage](https://www.kaggle.com/code/miftahuladib/housing-price-regression-top-4?scriptVersionId=202452540)\n",
    "\n",
    "Feature Engineering\n",
    "\n",
    "1. Sum features (like baths, porcharea, rooms)\n",
    "2. Year features (ex. transform to 2025 - yearbuilt)\n",
    "3. Fill NA Values (simply fill with 0 or 'No')\n",
    "\n",
    "Additional Engineering\n",
    "\n",
    "1. Remove Outliers (based on scatterplots of various numerical features)\n",
    "2. Column Transformer (numeric --> standardScalar, ordinal --> ordinalEncoder, categorical --> oneHotEncoded)\n",
    "\n",
    "Modelling\n",
    "\n",
    "1. Random forest regressor\n",
    "2. XGBoost\n",
    "3. Ridge regression\n",
    "4. Light GBM\n",
    "5. CatBoost\n",
    "6. VotingRegressor (not used)\n",
    "7. StackingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals and Plan\n",
    "\n",
    "Goal: Understand which components of the other submissions are most relevant (how they affect score)\n",
    "\n",
    "These components include:\n",
    "\n",
    "1. Feature Engineering (which new features are best: summed features, year features, has features)\n",
    "2. Feature Transformation and Filling (boxcox transformation, fill na with null vs. values)\n",
    "3. Data leakage (how much does it help)\n",
    "\n",
    "4. Column Transformers (scaling, ordinal transform vs. one hot encoding)\n",
    "5. Removing outliers\n",
    "\n",
    "6. Model blending\n",
    "\n",
    "Base model:\n",
    "1. All possible engineered features\n",
    "2. No boxcox transformations, fill na with 0/'No'\n",
    "3. No scaling, all ordinal transform\n",
    "4. No outlier removal\n",
    "5. XGBoost only\n",
    "\n",
    "Unilaterally change the following and Record Test Score:\n",
    "1. Removing engineered features\n",
    "2. Boxcox transformation (with and without data leakage)\n",
    "3. Scaling + Separate ordinal and One Hot Transformations\n",
    "4. Outlier removal\n",
    "5. Models blended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.linear_model import Ridge, Lasso, RidgeCV, LassoCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import make_scorer,root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './data/train.csv'\n",
    "df = pd.read_csv(train_path)\n",
    "X, Y = df.drop(labels=['SalePrice'], axis=1), np.log1p(df['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NA\n",
    "\n",
    "numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "def fillNull(X):\n",
    "    for col in X.columns:\n",
    "        if X[col].dtype in numeric_dtypes: X[col] = X[col].fillna(0)\n",
    "        else: X[col] = X[col].fillna('No')\n",
    "\n",
    "fillNull(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering (simply taken from other Kaggle submissions, goal is to see effectiveness)\n",
    "\n",
    "def featureEngineering(X: pd.DataFrame):\n",
    "    # Summed features\n",
    "    X['YrBltAndRemod']=X['YearBuilt']+X['YearRemodAdd']\n",
    "    X['TotalSF']=X['TotalBsmtSF'] + X['1stFlrSF'] + X['2ndFlrSF']\n",
    "    X['Total_sqr_footage'] = (X['BsmtFinSF1'] + X['BsmtFinSF2'] +\n",
    "                                    X['1stFlrSF'] + X['2ndFlrSF'])\n",
    "    X['Total_Bathrooms'] = (X['FullBath'] + (0.5 * X['HalfBath']) +\n",
    "                                X['BsmtFullBath'] + (0.5 * X['BsmtHalfBath']))\n",
    "    X['Total_porch_sf'] = (X['OpenPorchSF'] + X['3SsnPorch'] +\n",
    "                                X['EnclosedPorch'] + X['ScreenPorch'] +\n",
    "                                X['WoodDeckSF'])\n",
    "\n",
    "    # Has features\n",
    "    X['haspool'] = X['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    X['has2ndfloor'] = X['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    X['hasgarage'] = X['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    X['hasbsmt'] = X['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    X['hasfireplace'] = X['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "featureEngineering(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_model(modelTuple, params):\n",
    "    categorical_cols = [col for col in X.columns if X[col].dtype not in numeric_dtypes]\n",
    "    numerical_cols = [col for col in X.columns if X[col].dtype in numeric_dtypes]\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('encoder', ColumnTransformer([\n",
    "            ('scalar', RobustScaler(), numerical_cols),\n",
    "            ('ohe', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "        ], remainder='passthrough')),\n",
    "        \n",
    "        modelTuple\n",
    "    ])\n",
    "\n",
    "    gridsearch = GridSearchCV(\n",
    "        pipeline,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        param_grid=params,\n",
    "        n_jobs=-1,\n",
    "        cv=5,\n",
    "        return_train_score=True\n",
    "    )\n",
    "\n",
    "    gridsearch.fit(X, Y)\n",
    "\n",
    "    results = pd.DataFrame(gridsearch.cv_results_['params'])\n",
    "    results['train_rmse'] = gridsearch.cv_results_['mean_train_score']\n",
    "    results['test_rmse'] = gridsearch.cv_results_['mean_test_score']\n",
    "    results = results.sort_values(by='test_rmse', ascending=False)\n",
    "    display(results.head())\n",
    "\n",
    "    return gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 31\u001b[0m\n\u001b[1;32m     16\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxgb__n_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m500\u001b[39m,\u001b[38;5;241m3000\u001b[39m],\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxgb__learning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.005\u001b[39m, \u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.1\u001b[39m],\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxgb__max_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m     20\u001b[0m     }\n\u001b[1;32m     22\u001b[0m gridsearch \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[1;32m     23\u001b[0m     pipeline,\n\u001b[1;32m     24\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_root_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m     return_train_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     )\n\u001b[0;32m---> 31\u001b[0m \u001b[43mgridsearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# View results\u001b[39;00m\n\u001b[1;32m     34\u001b[0m results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(gridsearch\u001b[38;5;241m.\u001b[39mcv_results_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/tradingClub/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tradingClub/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1015\u001b[0m     )\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/tradingClub/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1573\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tradingClub/lib/python3.12/site-packages/sklearn/model_selection/_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    962\u001b[0m         )\n\u001b[1;32m    963\u001b[0m     )\n\u001b[0;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    988\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/tradingClub/lib/python3.12/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tradingClub/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tradingClub/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tradingClub/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# XGB\n",
    "categorical_cols = [col for col in X.columns if X[col].dtype not in numeric_dtypes]\n",
    "numerical_cols = [col for col in X.columns if X[col].dtype in numeric_dtypes]\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('encoder', ColumnTransformer([\n",
    "        ('scalar', RobustScaler(), numerical_cols),\n",
    "        ('ohe', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ], remainder='passthrough')),\n",
    "    \n",
    "    ('xgb', xgb.XGBRegressor(\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'xgb__n_estimators': [100,500,3000],\n",
    "    'xgb__learning_rate': [0.005, 0.01, 0.1],\n",
    "    'xgb__max_depth': [3]\n",
    "    }\n",
    "\n",
    "gridsearch = GridSearchCV(\n",
    "    pipeline,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    param_grid=params,\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    return_train_score=True\n",
    "    )\n",
    "\n",
    "gridsearch.fit(X, Y)\n",
    "\n",
    "# View results\n",
    "results = pd.DataFrame(gridsearch.cv_results_['params'])\n",
    "results['train_rmse'] = gridsearch.cv_results_['mean_train_score']\n",
    "results['test_rmse'] = gridsearch.cv_results_['mean_test_score']\n",
    "results = results.sort_values(by='test_rmse', ascending=False)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ridge__alpha</th>\n",
       "      <th>ridge__solver</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>19</td>\n",
       "      <td>sag</td>\n",
       "      <td>-0.112776</td>\n",
       "      <td>-0.138088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>19</td>\n",
       "      <td>sparse_cg</td>\n",
       "      <td>-0.112776</td>\n",
       "      <td>-0.138088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>19</td>\n",
       "      <td>auto</td>\n",
       "      <td>-0.112776</td>\n",
       "      <td>-0.138088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18</td>\n",
       "      <td>sparse_cg</td>\n",
       "      <td>-0.112445</td>\n",
       "      <td>-0.138090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18</td>\n",
       "      <td>sag</td>\n",
       "      <td>-0.112445</td>\n",
       "      <td>-0.138090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18</td>\n",
       "      <td>auto</td>\n",
       "      <td>-0.112445</td>\n",
       "      <td>-0.138090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>auto</td>\n",
       "      <td>-0.112104</td>\n",
       "      <td>-0.138094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17</td>\n",
       "      <td>sparse_cg</td>\n",
       "      <td>-0.112104</td>\n",
       "      <td>-0.138094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>sag</td>\n",
       "      <td>-0.112104</td>\n",
       "      <td>-0.138094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>auto</td>\n",
       "      <td>-0.111717</td>\n",
       "      <td>-0.138118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>sag</td>\n",
       "      <td>-0.111717</td>\n",
       "      <td>-0.138118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>sparse_cg</td>\n",
       "      <td>-0.111717</td>\n",
       "      <td>-0.138118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20</td>\n",
       "      <td>auto</td>\n",
       "      <td>-0.113097</td>\n",
       "      <td>-0.138163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>sparse_cg</td>\n",
       "      <td>-0.113097</td>\n",
       "      <td>-0.138163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>sag</td>\n",
       "      <td>-0.113097</td>\n",
       "      <td>-0.138163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>-0.119210</td>\n",
       "      <td>-0.140644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>19</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>-0.119136</td>\n",
       "      <td>-0.140683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>-0.119064</td>\n",
       "      <td>-0.140726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>-0.118399</td>\n",
       "      <td>-0.141129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>-0.118325</td>\n",
       "      <td>-0.141192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ridge__alpha ridge__solver  train_rmse  test_rmse\n",
       "15            19           sag   -0.112776  -0.138088\n",
       "14            19     sparse_cg   -0.112776  -0.138088\n",
       "12            19          auto   -0.112776  -0.138088\n",
       "10            18     sparse_cg   -0.112445  -0.138090\n",
       "11            18           sag   -0.112445  -0.138090\n",
       "8             18          auto   -0.112445  -0.138090\n",
       "4             17          auto   -0.112104  -0.138094\n",
       "6             17     sparse_cg   -0.112104  -0.138094\n",
       "7             17           sag   -0.112104  -0.138094\n",
       "0             16          auto   -0.111717  -0.138118\n",
       "3             16           sag   -0.111717  -0.138118\n",
       "2             16     sparse_cg   -0.111717  -0.138118\n",
       "16            20          auto   -0.113097  -0.138163\n",
       "18            20     sparse_cg   -0.113097  -0.138163\n",
       "19            20           sag   -0.113097  -0.138163\n",
       "17            20          lsqr   -0.119210  -0.140644\n",
       "13            19          lsqr   -0.119136  -0.140683\n",
       "9             18          lsqr   -0.119064  -0.140726\n",
       "5             17          lsqr   -0.118399  -0.141129\n",
       "1             16          lsqr   -0.118325  -0.141192"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "categorical_cols = [col for col in X.columns if X[col].dtype not in numeric_dtypes]\n",
    "numerical_cols = [col for col in X.columns if X[col].dtype in numeric_dtypes]\n",
    "\n",
    "param_grid_ridge = {\n",
    "    'ridge__alpha': [16,17,18,19,20],\n",
    "    'ridge__solver': ['auto', 'lsqr', 'sparse_cg', 'sag']\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('encoder', ColumnTransformer([\n",
    "        ('scalar', RobustScaler(), numerical_cols),\n",
    "        ('ohe', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ], remainder='passthrough')),\n",
    "    \n",
    "    ('ridge', Ridge())\n",
    "])\n",
    "\n",
    "gridsearch = GridSearchCV(\n",
    "    pipeline,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    param_grid=param_grid_ridge,\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    return_train_score=True\n",
    "    )\n",
    "\n",
    "gridsearch.fit(X, Y)\n",
    "\n",
    "# View results\n",
    "results = pd.DataFrame(gridsearch.cv_results_['params'])\n",
    "results['train_rmse'] = gridsearch.cv_results_['mean_train_score']\n",
    "results['test_rmse'] = gridsearch.cv_results_['mean_test_score']\n",
    "results = results.sort_values(by='test_rmse', ascending=False)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13418579739329983"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_model(model):\n",
    "    test_path = './data/test.csv'\n",
    "    test_df = pd.read_csv(test_path)\n",
    "    fillNull(test_df)\n",
    "    featureEngineering(test_df)\n",
    "\n",
    "    test_y = model.predict(test_df)\n",
    "\n",
    "    test_df['SalePrice'] = np.expm1(test_y)\n",
    "    test_df[['Id', 'SalePrice']].to_csv('results.csv', index=False)\n",
    "\n",
    "    solution_path = './data/solution.csv'\n",
    "    solution_df = pd.read_csv(solution_path)\n",
    "    score = root_mean_squared_error(np.log(test_df['SalePrice']), np.log(solution_df['SalePrice']))\n",
    "    return score\n",
    "\n",
    "test_model(gridsearch.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "Feature Engineering:\n",
    "1. No feature engineering: 0.1345\n",
    "2. Summed features: 0.1307\n",
    "3. Has features: 0.1345\n",
    "\n",
    "Scaling:\n",
    "1. Baseline ordinal encoding:  0.1307\n",
    "2. One hot encoding (instead of ordinal): 0.1317\n",
    "3. One hot + Robust scalar: 0.1309\n",
    "\n",
    "Models:\n",
    "1. XGB: 0.1309\n",
    "2. Ridge regression: 0.134"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tradingClub",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
